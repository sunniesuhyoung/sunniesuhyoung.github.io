<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<title>Sunnie S. Y. Kim</title>
	<meta name="keywords" content="Sunnie S. Y. Kim, Sunnie S. Y. Kim Princeton, Sunnie S. Y. Kim Research">
	<meta name="description" content="Sunnie S. Y. Kim, Personal Website">
	<meta name="author" content="Sunnie S. Y. Kim">
	<link rel="icon" type="image/png" href="sun.png">

	<!-- Bootstrap Core CSS -->
	<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">

	<!-- Custom CSS -->
	<link href="css/custom.css" rel="stylesheet">

	<!-- Custom Fonts -->
	<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
	
	<!-- Custom JavaScript -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
	<style>
	</style>
</head>

<body id="page-top" class="index">
	<!-- Portfolio -->
	<section id="portfolio">
		<div class="container">

	
			<div class="row margin-top-xl">
				<div class="col-sm-2">
					<img class="dp" src="sunnie.png">
				</div>
				<div class="col-sm-5">
					<h2 class="title">Sunnie<br>S. Y. Kim</h2>
				</div>
			</div>

			<div class="row">
				<div class="col-sm-7 margin-top-sm">
					<div class="info">
						<div>
							<a href="/">
								<p class="margin-top-sm intro" style="font-family:'AvenirNext-DemiBold';color:#e76f51;font-size:16px">
									<i class="fa fa-home"></i> HOME
								</p>
							</a>
						</div>
					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">Full list of papers</h2>
						<p class="margin-top-xs">
							I primarily do research on responsible AI and human-AI interaction.
							But I have also done other research with collaborators in psychology, neuroscience, environmental science, and art.
							I really enjoy and value interdisciplinary research.
						</p>
					</div>
				</div>
			</div>

			

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">

						<h2 class="page-title">2025</h2>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2509.03728" style="font-family:AvenirNext-DemiBold" target="_blank">
									PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming
								</a>
							</span><br>
							<span class="authors">Wesley Hanwen Deng, <span class="self">Sunnie S. Y. Kim</span>, Akshita Jha, Ken Holstein, Motahhare Eslami, Lauren Wilcox, Leon A Gatys</span><br>
							<span class="venue">
<!-- 								<span class="paper-award">Venue</span> &#x25CF  -->
								<a href="https://arxiv.org/abs/2509.03728" target="_blank">PAPER</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://sunniesuhyoung.github.io/Dissertation_SunnieSYKim.pdf" style="font-family:AvenirNext-DemiBold" target="_blank">
									Advancing Responsible AI with Human-Centered Evaluation
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span></span><br>
							<span class="venue">
								<span class="paper-award">Princeton University PhD Dissertation</span> &#x25CF 
								<a href="https://sunniesuhyoung.github.io/Dissertation_SunnieSYKim.pdf" target="_blank">PAPER</a>
							</span>
						</p>
						
						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2502.08554" style="font-family:AvenirNext-DemiBold" target="_blank">
									Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Jennifer Wortman Vaughan, Q. Vera Liao, Tania Lombrozo, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">CHI 2025  <i class="fa fa-trophy" aria-hidden="true"></i>  HONORABLE MENTION </span> &#x25CF
								<a href="https://arxiv.org/abs/2502.08554" target="_blank">PAPER</a> &#x25CF
								<a href="https://youtu.be/2VI1Za33lZE" target="_blank">TALK</a>
							</span>
							<p class="note">
								* Featured in Microsoft's <a href="https://www.microsoft.com/en-us/research/publication/microsoft-new-future-of-work-report-2024/" style="font-size:11px" target="_blank">New Future of Work</a> report 
								and presented at 10+ places through invited and contributed talks.
							</p>
						</p>


						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://cogtoolslab.github.io/pdf/chen_chilbw_2025.pdf" style="font-family:AvenirNext-DemiBold" target="_blank">
									Portraying Large Language Models as Machines, Tools, or Companions Affects What Mental Capacities Humans Attribute to Them
								</a>
							</span><br>
							<span class="authors">Allison Chen, <span class="self">Sunnie S. Y. Kim</span>, Amaya Dharmasiri, Olga Russakovsky, Judith E. Fan</span><br>
							<span class="venue">
								<span class="paper-award">CHI 2025 Late Breaking Work & CogSci 2025 </span>  &#x25CF
								<a href="https://cogtoolslab.github.io/pdf/chen_chilbw_2025.pdf" target="_blank">PAPER</a>
							</span>
						</p>

						
						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="http://arxiv.org/abs/2504.10745" style="font-family:AvenirNext-DemiBold" target="_blank">
									Interactivity x Explainability: Understanding How Interactivity Can Improve Computer Vision Explanations
								</a>
							</span><br>
							<span class="authors">Indu Panigrahi, <span class="self">Sunnie S. Y. Kim</span>*, Amna Liaqat*, Rohan Jinturkar, Olga Russakovsky, Ruth Fong, Parastoo Abtahi</span><br>
							<span class="venue">
								<span class="paper-award">CHI 2025 Late Breaking Work</span>  &#x25CF
								<a href="http://arxiv.org/abs/2504.10745" target="_blank">PAPER</a>   &#x25CF
								<a href="https://ind1010.github.io/interactive_XAI" target="_blank">WEBSITE</a>
								
							</span>
						</p>

					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						
						<h2 class="page-title">2024</h2>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://dl.acm.org/doi/10.1145/3630106.3658941" style="font-family:AvenirNext-DemiBold" target="_blank">
									"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Q. Vera Liao, Mihaela Vorvoreanu, Stephanie Ballard, Jennifer Wortman Vaughan</span><br>
							<span class="venue">
								<span class="paper-award">FAccT 2024</span> &#x25CF 
								<a href="https://dl.acm.org/doi/10.1145/3630106.3658941" target="_blank">PAPER</a> &#x25CF 
								<a href="https://osf.io/mnrp9" target="_blank">OSF</a> 
							</span>
							<p class="note">
								* Featured in <a href="https://www.axios.com/2024/06/21/ai-chatbots-uncertainty-hallucinations-detection" style="font-size:11px" target="_blank">Axios</a>, 
								<a href="https://www.newscientist.com/article/2429701-people-are-less-likely-to-believe-an-ai-if-it-conveys-uncertainty/" style="font-size:11px" target="_blank">New Scientist</a>, 
								<a href="https://link.growkudos.com/1eh9zy811xc" style="font-size:11px" target="_blank">ACM showcase</a>, 
								Microsoft's <a href="https://www.microsoft.com/en-us/research/publication/microsoft-new-future-of-work-report-2024/" style="font-size:11px" target="_blank">New Future of Work</a>
								and <a href="https://www.microsoft.com/en-us/corporate-responsibility/responsible-ai-transparency-report/" style="font-size:11px" target="_blank">Responsible AI Transparency</a> reports, 
								and the Human-Centered AI Medium publication as <a href="https://medium.com/human-centered-ai/new-editors-good-reads-in-human-centered-ai-cc7380a2eee3" style="font-size:11px" target="_blank">Good Reads in Human-Centered AI</a>.
							</p>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2404.05238" style="font-family:AvenirNext-DemiBold" target="_blank">
									Allowing Humans to Interactively Guide Machines Where to Look Does Not Always Improve Human-AI Team's Classification Accuracy
								</a>
							</span><br>
							<span class="authors">Giang Nguyen, Mohammad Reza Taesiri, <span class="self">Sunnie S. Y. Kim</span>, Anh Totti Nguyen</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2024 Workshop</span> &#x25CF 
								<a href="https://arxiv.org/abs/2404.05238" target="_blank">PAPER</a> &#x25CF 
								<a href="https://github.com/anguyen8/chm-corr-interactive" target="_blank">CODE</a> &#x25CF 
								<a href="http://137.184.82.109:7080/" target="_blank">DEMO</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://doi.org/10.1145/3613905.3638184" style="font-family:AvenirNext-DemiBold" target="_blank">
									Establishing Appropriate Trust in AI through Transparency and Explainability
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span></span><br>
							<span class="venue">
								<span class="paper-award">CHI 2024 Doctoral Consortium</span> &#x25CF 
								<a href="https://doi.org/10.1145/3613905.3638184" target="_blank">PAPER</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://doi.org/10.1145/3613905.3636311" style="font-family:AvenirNext-DemiBold" target="_blank">
									Human-Centered Explainable AI (HCXAI): Reloading Explainability in the Era of Large Language Models (LLMs)
								</a>
							</span><br>
							<span class="authors">Upol Ehsan, Elizabeth Anne Watkins, Philipp Wintersberger, Carina Manger, <span class="self">Sunnie S. Y. Kim</span>, Niels van Berkel, Andreas Riener, Mark O. Riedl</span><br>
							<span class="venue">
								<span class="paper-award">CHI 2024 Workshop Proposal</span> &#x25CF 
								<a href="https://doi.org/10.1145/3613905.3636311" target="_blank">PAPER</a>
							</span>
						</p>

					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2023</h2>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://dl.acm.org/doi/10.1145/3544548.3581001" style="font-family:AvenirNext-DemiBold" target="_blank">
									"Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, Andrés Monroy-Hernández</span><br>
							<span class="venue">
								<span class="paper-award">CHI 2023 <i class="fa fa-trophy" aria-hidden="true"></i> HONORABLE MENTION</span> &#x25CF 
								<a href="https://dl.acm.org/doi/10.1145/3544548.3581001" target="_blank">PAPER</a> &#x25CF 
								<a href="https://sunniesuhyoung.github.io/XAI_Trust/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://youtu.be/IcVsi5-ON4Y" target="_blank">TALK</a>
							</span>
							<p class="note">
								* One of the top 10 cited CHI papers in 2023-2024 (as of Dec 2024).
								Featured in the Human-Centered AI Medium publication as <a href="https://medium.com/human-centered-ai/chi-2023-editors-choice-359ffae60706" style="font-size:11px" target="_blank">CHI 2023 Editors' Choice</a>.
								Also presented at the NeurIPS 2022 Human-Centered AI Workshop (<b>spotlight</b>), 
								CHI 2023 Human-Centered Explainable AI Workshop (<b>spotlight</b>), 
								ECCV 2024 Explainable Computer Vision Workshop (<b>invited talk</b>), 
								and NYC Computer Vision Day 2024 (<b>lightning talk</b>.
							</p>
						</p>
							
						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://dl.acm.org/doi/10.1145/3593013.3593978" style="font-family:AvenirNext-DemiBold" target="_blank">
									Humans, AI, and Context: Understanding End-Users’ Trust in a Real-World Computer Vision Application
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, Andrés Monroy-Hernández</span><br>
							<span class="venue">
								<span class="paper-award">FAccT 2023</span> &#x25CF
								<a href="https://dl.acm.org/doi/10.1145/3593013.3593978" target="_blank">PAPER</a> &#x25CF 
								<a href="https://princetonvisualai.github.io/HIVE/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://youtu.be/2e1frsZ0NDw" target="_blank">TALK</a>
							</span>
							<p class="note">
								* Featured in the Montreal AI Ethics Institute's 
								<a href="https://montrealethics.ai/humans-ai-and-context-understanding-end-users-trust-in-a-real-world-computer-vision-application/" style="font-size:11px" target="_blank">blog</a>.
								Also presented at the CHI 2023 Trust and Reliance in AI-assisted Tasks Workshop.
							</p>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2207.09615" style="font-family:AvenirNext-DemiBold" target="_blank">
									Overlooked Factors in Concept-based Explanations: Dataset Choice, Concept Learnability, and Human Capability
								</a>
							</span><br>
							<span class="authors">Vikram V. Ramaswamy, <span class="self">Sunnie S. Y. Kim</span>, Ruth Fong, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2023</span> &#x25CF 
								<a href="https://arxiv.org/abs/2207.09615" target="_blank">PAPER</a> &#x25CF 
								<a href="https://github.com/princetonvisualai/OverlookedFactors" target="_blank">CODE</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2303.15632" style="font-family:AvenirNext-DemiBold" target="_blank">
									UFO: A Unified Method for Controlling Understandability and Faithfulness Objectives in Concept-based Explanations for CNNs
								</a>
							</span><br>
							<span class="authors">Vikram V. Ramaswamy, <span class="self">Sunnie S. Y. Kim</span>, Ruth Fong, Olga Russakovsky</span><br>
							<span class="venue">
								<a href="https://arxiv.org/abs/2303.15632" target="_blank">PAPER</a>
							</span>
						</p>

					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2022</h2>
						
						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2112.03184" style="font-family:AvenirNext-DemiBold" target="_blank">
									HIVE: Evaluating the Human Interpretability of Visual Explanations
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Nicole Meister, Vikram V. Ramaswamy, Ruth Fong, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">ECCV 2022</span> &#x25CF
								<a href="https://arxiv.org/abs/2112.03184" target="_blank">PAPER</a> &#x25CF 
								<a href="https://princetonvisualai.github.io/HIVE/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://github.com/princetonvisualai/HIVE" target="_blank">CODE</a> &#x25CF 
								<a href="https://youtu.be/7uysq-qAtr4" target="_blank">TALK</a>
							</span>
							<p class="note">
								* Also presented at the CVPR 2022 Explainable AI for Computer Vision Workshop (<b>spotlight</b>), 
								CHI 2022 Human-Centered Explainable AI Workshop (<b>spotlight</b>), 
								and CVPR 2022 Women in Computer Vision Workshop.
							</p>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2206.07690" style="font-family:AvenirNext-DemiBold" target="_blank">
									ELUDE: Generating Interpretable Explanations via a Decomposition into Labelled and Unlabelled Features
								</a>
							</span><br>
							<span class="authors">Vikram V. Ramaswamy, <span class="self">Sunnie S. Y. Kim</span>, Ruth Fong, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2022 Workshop</span> &#x25CF 
								<a href="https://arxiv.org/abs/2206.07690" target="_blank">PAPER</a>
							</span>
						</p>

						<p class="margin-top-sm" id="neuro">
							<span class="paper-title">
								<a href="https://doi.org/10.7554/eLife.72067" style="font-family:AvenirNext-DemiBold" target="_blank">
									Shallow Neural Networks Trained to Detect Collisions Recover Features of Visual Loom-Selective Neurons
								</a>
							</span><br>
							<span class="authors">Baohua Zhou, Zifan Li, <span class="self">Sunnie S. Y. Kim</span>, John Lafferty, Damon A. Clark</span><br>
							<span class="venue">
								<span class="paper-award">eLife 2022</span> &#x25CF 
								<a href="https://doi.org/10.7554/eLife.72067" target="_blank">PAPER</a> &#x25CF 
								<a href="https://github.com/ClarkLabCode/LoomDetectionANN" target="_blank">CODE</a>
							</span>
						</p>

					</div>
				</div>
			</div>

			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2021</h2>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2012.01469" style="font-family:AvenirNext-DemiBold" target="_blank">
									Fair Attribute Classification through Latent Space De-biasing
								</a>
							</span><br>
							<span class="authors">Vikram V. Ramaswamy, <span class="self">Sunnie S. Y. Kim</span>, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2021</span> &#x25CF
								<a href="https://arxiv.org/abs/2012.01469" target="_blank">PAPER</a> &#x25CF 
								<a href="https://princetonvisualai.github.io/gan-debiasing/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://github.com/princetonvisualai/gan-debiasing" target="_blank">CODE</a> &#x25CF 
								<a href="https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C2W2_GAN_Debiasing_(Optional).ipynb" target="_blank">DEMO</a> &#x25CF 
								<a href="https://youtu.be/1ebHTCQRNs4" target="_blank">TALK</a>
							</span>
							<p class="note">
								* Featured in Coursera's <a href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" style="font-size:11px" target="_blank">GANs Specialization</a> course 
								and the MIT Press book <a href="https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/" style="font-size:11px" target="_blank">Foundations of Computer Vision</a>.
								Also presented at the CVPR 2021 Responsible Computer Vision Workshop (<b>invited talk</b>) 
								and CVPR 2021 Women in Computer Vision Workshop (<b>invited talk</b>).
							</p>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2012.07287" style="font-family:AvenirNext-DemiBold" target="_blank">
									Information-Theoretic Segmentation by Inpainting Error Maximization
								</a>
							</span><br>
							<span class="authors">Pedro Savarese, <span class="self">Sunnie S. Y. Kim</span>, Michael Maire, Gregory Shakhnarovich, David McAllester</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2021</span> &#x25CF 
								<a href="https://arxiv.org/abs/2012.07287" target="_blank">PAPER</a> &#x25CF 
								<a href="https://lolemacs.github.io/iem/" target="_blank">WEBSITE</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="http://arxiv.org/abs/2106.00815" style="font-family:AvenirNext-DemiBold" target="_blank">
									Cleaning and Structuring the Label Space of the iMet Collection 2020
								</a>
							</span><br>
							<span class="authors">Vivien Nguyen*, <span class="self">Sunnie S. Y. Kim</span>*</span><br>
							<span class="venue">
								<span class="paper-award">CVPR 2021 Workshop</span> &#x25CF 
								<a href="http://arxiv.org/abs/2106.00815" target="_blank">PAPER</a> &#x25CF 
								<a href="https://github.com/sunniesuhyoung/iMet2020cleaned" target="_blank">CODE</a>
							</span>
						</p>

						<p class="margin-top-sm">
							<span class="paper-title">
								<a href="http://arxiv.org/abs/2104.13582" style="font-family:AvenirNext-DemiBold" target="_blank">
									[Re] Don't Judge an Object by Its Context: Learning to Overcome Contextual Bias
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Sharon Zhang, Nicole Meister, Olga Russakovsky</span><br>
							<span class="venue">
								<span class="paper-award">ReScience 2021</span> &#x25CF 
								<a href="http://arxiv.org/abs/2104.13582" target="_blank">PAPER</a> &#x25CF 
								<a href="https://github.com/sunniesuhyoung/ContextualBias" target="_blank">CODE</a>
							</span>
							<p class="note">
								* Selected for publication from the <a href="https://paperswithcode.com/rc2020" style="font-size:11px" target="_blank">ML Reproducibility Challenge 2020</a>.
							</p>
						</p>
						
					</div>
				</div>
			</div>


			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2020</h2>

						<p class="margin-top-sm" id="art">
							<span class="paper-title">
								<a href="https://arxiv.org/abs/2003.11038" style="font-family:AvenirNext-DemiBold" target="_blank">
									Deformable Style Transfer
								</a>
							</span><br>
							<span class="authors"><span class="self">Sunnie S. Y. Kim</span>, Nicholas Kolkin, Jason Salavon, Gregory Shakhnarovich</span><br>
							<span class="venue">
								<span class="paper-award">ECCV 2020</span> &#x25CF 
								<a href="https://arxiv.org/abs/2003.11038" target="_blank">PAPER</a> &#x25CF 
								<a href="https://sunniesuhyoung.github.io/DST-page/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://github.com/sunniesuhyoung/DST" target="_blank">CODE</a> &#x25CF 
								<a href="https://bit.ly/DST-demo" target="_blank">DEMO</a> &#x25CF 
								<a href="https://youtu.be/mVU5tSxS4is" target="_blank">TALK</a>
							</span>
							<p class="note">
								* Received 260+ stars on GitHub. Also presented at the ECCV 2020 Women in Computer Vision Workshop.
							</p>
						</p>

					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2019</h2>

						<p class="margin-top-sm" id="psych">
							<span class="paper-title">
								<a href="http://journal.sjdm.org/19/190705a/jdm190705a.pdf" style="font-family:AvenirNext-DemiBold" target="_blank">
									Which Grades are Better, A’s and C’s, or All B’s? Effects of Variability in Grades on Mock College Admissions Decisions
								</a>
							</span><br>
							<span class="authors">Woo-kyoung Ahn, <span class="self">Sunnie S. Y. Kim</span>, Kristen Kim, Peter K. McNally</span><br>
							<span class="venue">
								<span class="paper-award">JDM 2019</span> &#x25CF 
								<a href="http://journal.sjdm.org/19/190705a/jdm190705a.pdf" target="_blank">PAPER</a>
							</span>
						</p>

					</div>
				</div>
			</div>

			
			<div class="row">
				<div class="col-sm-7 margin-top-md">
					<div class="projects">
						<h2 class="page-title">2018</h2>

						<p class="margin-top-sm" id="env">
							<span class="paper-title">
								<a href="https://epi.yale.edu/" style="font-family:AvenirNext-DemiBold" target="_blank">
									Environmental Performance Index
								</a>
							</span><br>
							<span class="authors">Zachary A. Wendling, Daniel C. Esty, John W. Emerson, Marc A. Levy, Alex de Sherbinin, ..., <span class="self">Sunnie S. Y. Kim</span> et al.</span><br>
							<span class="venue">
								<span class="paper-award">WORLD ECONOMIC FORUM 2018</span> &#x25CF 
								<a href="https://sedac.ciesin.columbia.edu/data/set/epi-environmental-performance-index-2018" target="_blank">PAPER</a> &#x25CF 
								<a href="https://epi.yale.edu/" target="_blank">WEBSITE</a> &#x25CF 
								<a href="https://www.weforum.org/agenda/2018/01/why-we-should-welcome-the-new-era-of-data-in-environmental-policy-making/" target="_blank">ARTICLE</a> &#x25CF 
								<a href="https://www.facebook.com/YaleUniversity/videos/10155902837400320/" target="_blank">DISCUSSION</a>
							</span>
							<p class="note">
								* Presented at the World Economic Forum. Covered by international media outlets.
								As the data team lead, I built the full data pipeline and led the analysis work.
							</p>
						</p>

					</div>
				</div>
			</div>


			<div class="row margin-top-xl">
			</div>
			
		</div>
	</section>


</body>

<!-- jQuery -->
<script src="js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="js/bootstrap.min.js"></script>

<!-- Plugin JavaScript -->
<script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
</html>
